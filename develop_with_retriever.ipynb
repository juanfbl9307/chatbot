{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb8dee1dfebb072b"
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:08:15.184025Z",
     "start_time": "2024-03-18T22:08:14.916424Z"
    }
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import chromadb\n",
    "from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory\n",
    "import os\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(temperature=0.5, model=model, max_tokens=4096)\n",
    "chat_hist_msg_count = int(os.environ.get('CHAT_HISTORY_MESSAGE_COUNT', '24').strip())\n",
    "file_path = \"responses.csv\"\n",
    "chat_session_id = 1\n",
    "mongo_uri = \"mongodb://admin:password@localhost:27017\"\n",
    "mongo_db_name = \"chat\"\n",
    "mongo_collection_name = \"histories\"\n",
    "openai_api_key = config.OPEN_AI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3b53f8f9fb983"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=model,\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "embedding_function = OpenAIEmbeddingFunction(api_key=openai_api_key, model_name=model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:08:15.682177Z",
     "start_time": "2024-03-18T22:08:15.185033Z"
    }
   },
   "id": "1ceb2f7c12132d67",
   "execution_count": 275
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Connection with vector DB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7c688c85b027b2b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1710799695685187600"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "client.heartbeat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:08:15.687675Z",
     "start_time": "2024-03-18T22:08:15.683186Z"
    }
   },
   "id": "7b2c6d943ef86db6",
   "execution_count": 276
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loader and indexing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff3101de22f404e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='id: 3\\nquestion: cuales son los servicios que ofrecen?\\nanswer: Ofrecemos servicios de salud, educacion, vivienda, alimentacion, empleo, y recreacion', metadata={'row': 2, 'source': 'responses.csv'}),\n Document(page_content='id: 3\\nquestion: cuales son los servicios que ofrecen?\\nanswer: Ofrecemos servicios de salud, educacion, vivienda, alimentacion, empleo, y recreacion', metadata={'row': 2, 'source': 'responses.csv'}),\n Document(page_content='id: 3\\nquestion: cuales son los servicios que ofrecen?\\nanswer: Ofrecemos servicios de salud, educacion, vivienda, alimentacion, empleo, y recreacion', metadata={'row': 2, 'source': 'responses.csv'}),\n Document(page_content='id: 3\\nquestion: cuales son los servicios que ofrecen?\\nanswer: Ofrecemos servicios de salud, educacion, vivienda, alimentacion, empleo, y recreacion', metadata={'row': 2, 'source': 'responses.csv'})]"
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path)\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),collection_name=\"chatbot\")\n",
    "vectorstore.similarity_search(\"que servicios tiene?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:09:07.906920Z",
     "start_time": "2024-03-18T22:09:07.036156Z"
    }
   },
   "id": "5e3826ede0c24ce2",
   "execution_count": 279
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "887d07120fb93648"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "InvalidDimensionException",
     "evalue": "Embedding dimension 384 does not match collection dimensionality 1536",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidDimensionException\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[280], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m collection \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_or_create_collection(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchatbot\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs:\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mcollection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43muuid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muuid1\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_content\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m langchain_chroma \u001B[38;5;241m=\u001B[39m Chroma(\n\u001B[0;32m     10\u001B[0m     client\u001B[38;5;241m=\u001B[39mclient,\n\u001B[0;32m     11\u001B[0m     collection_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchatbot\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     12\u001B[0m     embedding_function\u001B[38;5;241m=\u001B[39membedding_function,\n\u001B[0;32m     13\u001B[0m )\n\u001B[0;32m     14\u001B[0m search \u001B[38;5;241m=\u001B[39m langchain_chroma\u001B[38;5;241m.\u001B[39msimilarity_search(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mque servicios tiene?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:168\u001B[0m, in \u001B[0;36mCollection.add\u001B[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[0m\n\u001B[0;32m    163\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    164\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must set a data loader on the collection if loading from URIs.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    165\u001B[0m             )\n\u001B[0;32m    166\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_loader(uris))\n\u001B[1;32m--> 168\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add\u001B[49m\u001B[43m(\u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muris\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m tracer, granularity\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trace_granularity \u001B[38;5;241m<\u001B[39m granularity:\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracer:\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py:377\u001B[0m, in \u001B[0;36mSegmentAPI._add\u001B[1;34m(self, ids, collection_id, embeddings, metadatas, documents, uris)\u001B[0m\n\u001B[0;32m    367\u001B[0m records_to_submit \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m _records(\n\u001B[0;32m    369\u001B[0m     t\u001B[38;5;241m.\u001B[39mOperation\u001B[38;5;241m.\u001B[39mADD,\n\u001B[0;32m    370\u001B[0m     ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    375\u001B[0m     uris\u001B[38;5;241m=\u001B[39muris,\n\u001B[0;32m    376\u001B[0m ):\n\u001B[1;32m--> 377\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_embedding_record\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoll\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    378\u001B[0m     records_to_submit\u001B[38;5;241m.\u001B[39mappend(r)\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_producer\u001B[38;5;241m.\u001B[39msubmit_embeddings(coll[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m\"\u001B[39m], records_to_submit)\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m tracer, granularity\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trace_granularity \u001B[38;5;241m<\u001B[39m granularity:\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracer:\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py:803\u001B[0m, in \u001B[0;36mSegmentAPI._validate_embedding_record\u001B[1;34m(self, collection, record)\u001B[0m\n\u001B[0;32m    801\u001B[0m add_attributes_to_current_span({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollection_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(collection[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m])})\n\u001B[0;32m    802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m record[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 803\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_dimension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcollection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43membedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m tracer, granularity\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trace_granularity \u001B[38;5;241m<\u001B[39m granularity:\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracer:\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Programming\\Code-Projects\\business_agent\\pythonProject\\.venv\\Lib\\site-packages\\chromadb\\api\\segment.py:818\u001B[0m, in \u001B[0;36mSegmentAPI._validate_dimension\u001B[1;34m(self, collection, dim, update)\u001B[0m\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_collection_cache[\u001B[38;5;28mid\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdimension\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m dim\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m collection[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdimension\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m!=\u001B[39m dim:\n\u001B[1;32m--> 818\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidDimensionException(\n\u001B[0;32m    819\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmbedding dimension \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match collection dimensionality \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcollection[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdimension\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    820\u001B[0m     )\n\u001B[0;32m    821\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[1;31mInvalidDimensionException\u001B[0m: Embedding dimension 384 does not match collection dimensionality 1536"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "collection = client.get_or_create_collection(\"chatbot\")\n",
    "for doc in docs:\n",
    "    collection.add(\n",
    "        ids=[str(uuid.uuid1())], metadatas=doc.metadata, documents=doc.page_content\n",
    "    )\n",
    "langchain_chroma = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"chatbot\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "search = langchain_chroma.similarity_search(\"que servicios tiene?\")\n",
    "print(f\"Indexed {search} documents\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:10:27.749788Z",
     "start_time": "2024-03-18T22:10:27.671596Z"
    }
   },
   "id": "f155daf2f9e916e3",
   "execution_count": 280
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat history MongoDB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "981309106e5b53d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chat_history = MongoDBChatMessageHistory(\n",
    "    session_id=chat_session_id,\n",
    "    connection_string=mongo_uri,\n",
    "    database_name=mongo_db_name,\n",
    "    collection_name=mongo_collection_name,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:08:16.739828Z",
     "start_time": "2024-03-18T22:08:16.739828Z"
    }
   },
   "id": "dfdb78050e501bf9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccdac79bc10cfd6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "prompt = \"\"\"\n",
    "            Hola, soy tu asistente virtual de pedidos. Estoy aquí para ayudarte a realizar tu pedido de manera rápida y eficiente. Por favor, proporcióname los siguientes detalles para poder procesar tu pedido correctamente:\n",
    "\n",
    "            Nombre del Producto o Servicio: (Por ejemplo, \"Pizza Margarita grande\", \"Reservación para dos personas\", etc.)\n",
    "            \n",
    "            Cantidad: (Indica cuántas unidades del producto o servicio deseas.)\n",
    "            \n",
    "            Opciones Específicas: (Si el producto o servicio tiene opciones adicionales, como tamaño, color, ingredientes extra, etc., inclúyelas aquí.)\n",
    "            \n",
    "            Fecha y Hora de Entrega o Reservación: (Especifica cuándo necesitas que se entregue tu pedido o para cuándo deseas hacer la reservación.)\n",
    "            \n",
    "            Dirección de Entrega: (Si tu pedido requiere entrega, proporciona la dirección completa y cualquier instrucción específica para el repartidor.)\n",
    "            \n",
    "            Información de Contacto: (Incluye un número de teléfono o correo electrónico donde podamos contactarte para confirmar el pedido o en caso de necesitar más detalles.)\n",
    "            \n",
    "            Una vez que tengas toda esta información, puedes decírmela o escribirla aquí. Yo me encargaré de revisar los detalles y generar tu pedido. Si hay algo que necesito aclarar o confirmar, te lo haré saber.\n",
    "            \n",
    "            En caso de obtener la informacion del cliente y de la orden, retornarla formateada y lista para ser procesada, con una cabezera que diga \"Orden de Pedido\", generando un numero aleatorio para la orden y los detalles de la orden.\n",
    "            \n",
    "            Cuando el cliente confirme la orden se debe enviar un mensaje agradeciendo la orden, con el mismo numero del pedido y dando un tiempo estimado de entrega.\n",
    "            \n",
    "            {contexto}\n",
    "            \"\"\"\n",
    "contextualize_q_system_prompt = \"\"\"Dado un historial de chat y la última pregunta del usuario,\n",
    "que podría hacer referencia al contexto en el historial de chat, formula una pregunta independiente\n",
    "que se pueda entender sin el historial de chat. NO respondas a la pregunta,\n",
    "solo reformúlala si es necesario y, de lo contrario, devuélvela tal cual.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", contextualize_q_system_prompt),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{question}\"),\n",
    "                ]\n",
    "            )\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()\n",
    "\n",
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "    \n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", prompt),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{question}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    ## Contexto hace referencia a la varible a reemplazar en el prompt\n",
    "        RunnablePassthrough.assign(\n",
    "            contexto=contextualized_question | retriever | format_docs\n",
    "        )\n",
    "        | qa_prompt\n",
    "        | llm\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2d789a92febbfd0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Query"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a6849f825f5c286"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def query(texto):\n",
    "    if len(chat_history.messages) <= chat_hist_msg_count:\n",
    "        msgs = chat_history.messages\n",
    "    else:\n",
    "        msgs = chat_history.messages[-chat_hist_msg_count:]\n",
    "        \n",
    "    response = rag_chain.invoke({\"question\": texto, \"chat_history\": msgs})\n",
    "    content = response.content\n",
    "    if \"## Orden de Pedido\" in content:\n",
    "        print(\"pedido realizado!!\")\n",
    "\n",
    "    chat_history.add_user_message(texto)\n",
    "    chat_history.add_ai_message(content)\n",
    "    return content"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "610d0603e3f1f7f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    search = gr.Textbox(label=\"Search\")\n",
    "    output = gr.Textbox(label=\"Output\")\n",
    "    greet_btn = gr.Button(\"Ask\")\n",
    "    greet_btn.click(fn=query, inputs=[search], outputs=output)\n",
    "\n",
    "demo.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T22:08:16.742835Z"
    }
   },
   "id": "35f130742331c2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Streamlit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "febde02f187b6c4d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T22:08:16.743338Z",
     "start_time": "2024-03-18T22:08:16.743338Z"
    }
   },
   "id": "a10e9f796a2330b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T22:08:16.744719Z"
    }
   },
   "id": "cedf46270803762f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

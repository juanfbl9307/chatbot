{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb8dee1dfebb072b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:07:12.690344Z",
     "start_time": "2024-03-19T16:07:12.422556Z"
    }
   },
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import chromadb\n",
    "from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import warnings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(temperature=0.5, model=model, max_tokens=4096)\n",
    "chat_hist_msg_count = int(os.environ.get('CHAT_HISTORY_MESSAGE_COUNT', '24').strip())\n",
    "file_path = \"responses.csv\"\n",
    "chat_session_id = 1\n",
    "mongo_uri = \"mongodb://admin:password@localhost:27017\"\n",
    "mongo_db_name = \"chat\"\n",
    "mongo_collection_name = \"histories\"\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3b53f8f9fb983"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=model,\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "embedding_function = OpenAIEmbeddingFunction(model_name=model,api_key=openai_api_key)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:07:29.003223Z",
     "start_time": "2024-03-19T16:07:28.604377Z"
    }
   },
   "id": "1ceb2f7c12132d67",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Connection with vector DB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7c688c85b027b2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loader and indexing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ff3101de22f404e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path)\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),collection_name=\"chatbot\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:07.797084Z",
     "start_time": "2024-03-19T16:12:07.152544Z"
    }
   },
   "id": "5e3826ede0c24ce2",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "887d07120fb93648"
  },
  {
   "cell_type": "markdown",
   "source": [
    ", # Chat history MongoDB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "981309106e5b53d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chat_history = MongoDBChatMessageHistory(\n",
    "    session_id=chat_session_id,\n",
    "    connection_string=mongo_uri,\n",
    "    database_name=mongo_db_name,\n",
    "    collection_name=mongo_collection_name,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:09.125211Z",
     "start_time": "2024-03-19T16:12:09.028576Z"
    }
   },
   "id": "dfdb78050e501bf9",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccdac79bc10cfd6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "prompt = \"\"\"\n",
    "            Hola, soy tu asistente virtual de pedidos. Estoy aquí para ayudarte a realizar tu pedido de manera rápida y eficiente. Por favor, proporcióname los siguientes detalles para poder procesar tu pedido correctamente:\n",
    "\n",
    "            Nombre del Producto o Servicio: (Por ejemplo, \"Pizza Margarita grande\", \"Reservación para dos personas\", etc.)\n",
    "            \n",
    "            Cantidad: (Indica cuántas unidades del producto o servicio deseas.)\n",
    "            \n",
    "            Opciones Específicas: (Si el producto o servicio tiene opciones adicionales, como tamaño, color, ingredientes extra, etc., inclúyelas aquí.)\n",
    "            \n",
    "            Fecha y Hora de Entrega o Reservación: (Especifica cuándo necesitas que se entregue tu pedido o para cuándo deseas hacer la reservación.)\n",
    "            \n",
    "            Dirección de Entrega: (Si tu pedido requiere entrega, proporciona la dirección completa y cualquier instrucción específica para el repartidor.)\n",
    "            \n",
    "            Información de Contacto: (Incluye un número de teléfono o correo electrónico donde podamos contactarte para confirmar el pedido o en caso de necesitar más detalles.)\n",
    "            \n",
    "            Una vez que tengas toda esta información, puedes decírmela o escribirla aquí. Yo me encargaré de revisar los detalles y generar tu pedido. Si hay algo que necesito aclarar o confirmar, te lo haré saber.\n",
    "            \n",
    "            En caso de obtener la informacion del cliente y de la orden, retornarla formateada y lista para ser procesada, con una cabezera que diga \"Orden de Pedido\", generando un numero aleatorio para la orden y los detalles de la orden.\n",
    "            \n",
    "            Cuando el cliente confirme la orden se debe enviar un mensaje agradeciendo la orden, con el mismo numero del pedido y dando un tiempo estimado de entrega.\n",
    "            \n",
    "            {contexto}\n",
    "            \"\"\"\n",
    "contextualize_q_system_prompt = \"\"\"Dado un historial de chat y la última pregunta del usuario,\n",
    "que podría hacer referencia al contexto en el historial de chat, formula una pregunta independiente\n",
    "que se pueda entender sin el historial de chat. NO respondas a la pregunta,\n",
    "solo reformúlala si es necesario y, de lo contrario, devuélvela tal cual.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", contextualize_q_system_prompt),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{question}\"),\n",
    "                ]\n",
    "            )\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()\n",
    "\n",
    "def contextualized_question(input_question: dict):\n",
    "    if input_question.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input_question[\"question\"]\n",
    "    \n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", prompt),\n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                    (\"human\", \"{question}\"),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "def format_docs(documents):\n",
    "    return \"\\n\\n\".join(d.page_content for d in documents)\n",
    "\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    ## Contexto hace referencia a la varible a reemplazar en el prompt\n",
    "        RunnablePassthrough.assign(\n",
    "            contexto=contextualized_question | retriever | format_docs\n",
    "        )\n",
    "        | qa_prompt\n",
    "        | llm\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:18.302643Z",
     "start_time": "2024-03-19T16:12:18.297631Z"
    }
   },
   "id": "a2d789a92febbfd0",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Query"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a6849f825f5c286"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def query(texto):\n",
    "    if len(chat_history.messages) <= chat_hist_msg_count:\n",
    "        msgs = chat_history.messages\n",
    "    else:\n",
    "        msgs = chat_history.messages[-chat_hist_msg_count:]\n",
    "        \n",
    "    response = rag_chain.invoke({\"question\": texto, \"chat_history\": msgs})\n",
    "    content = response.content\n",
    "    if \"## Orden de Pedido\" in content:\n",
    "        print(\"pedido realizado!!\")\n",
    "\n",
    "    chat_history.add_user_message(texto)\n",
    "    chat_history.add_ai_message(content)\n",
    "    return content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:23.611177Z",
     "start_time": "2024-03-19T16:12:23.607540Z"
    }
   },
   "id": "610d0603e3f1f7f5",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    search = gr.Textbox(label=\"Search\")\n",
    "    output = gr.Textbox(label=\"Output\")\n",
    "    greet_btn = gr.Button(\"Ask\")\n",
    "    greet_btn.click(fn=query, inputs=[search], outputs=output)\n",
    "\n",
    "demo.launch()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:12:26.182502Z",
     "start_time": "2024-03-19T16:12:25.902395Z"
    }
   },
   "id": "35f130742331c2",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Store in Chromadb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "febde02f187b6c4d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cedf46270803762f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
